{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92eb038f-8d87-4ed5-b603-285eff593746",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ccefe4e-7f66-4068-8cf3-a966a811ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = os.path.join('..', 'POS_Tagging', 'data', 'train')\n",
    "TEST_PATH = os.path.join('..', 'POS_Tagging', 'data', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43013f91-96b4-47b5-a606-362f94e17eaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "909da2e424504efb9aa5474e4a20a347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('parquet', data_files=[*[os.path.join(TRAIN_PATH, f'train_{i}.parquet') for i in range(9)],\n",
    "                                    *[os.path.join(TEST_PATH, f'test_{i}.parquet') for i in range(9)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e1caa52-0806-4e81-9a97-749623f1cf22",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset.remove_columns(['init_words', 'pos_tags', 'sentence_length', 'unique_pos', 'starts_with'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e21f1ad7-f3b8-433a-82ef-3b56679d31a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = (sent['mod_words'] for sent in dataset['train'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "722ae6f9-f022-4d85-940d-2c9b40da580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reusable_sent():\n",
    "    \"\"\"\n",
    "    Makes a reusable iterable out of generator by remembering its arguments\n",
    "    \"\"\"\n",
    "    gen = (sent['mod_words'] for sent in dataset['train'])\n",
    "    \n",
    "    class MyIterable:\n",
    "    \n",
    "        def __iter__(self):\n",
    "            yield from gen\n",
    "\n",
    "    return MyIterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "34d67543-621b-4f76-97c9-74399205fb85",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'type' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m reusable_sent():\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(x)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'type' object is not iterable"
     ]
    }
   ],
   "source": [
    "for x in reusable_sent():\n",
    "    print(x)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "53024577-cee0-4665-b3c6-47316c9c8816",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "The corpus_iterable must be an iterable of lists of strings, got <class '__main__.reusable_sent.<locals>.MyIterable'> instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mWord2Vec\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreusable_sent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvector_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwindow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_count\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/word2vec.py:428\u001b[0m, in \u001b[0;36mWord2Vec.__init__\u001b[0;34m(self, sentences, corpus_file, vector_size, alpha, window, min_count, max_vocab_size, sample, seed, workers, min_alpha, sg, hs, negative, ns_exponent, cbow_mean, hashfxn, epochs, null_word, trim_rule, sorted_vocab, batch_words, compute_loss, callbacks, comment, max_final_vocab, shrink_windows)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload \u001b[38;5;241m=\u001b[39m call_on_class_only\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m corpus_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 428\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_corpus_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcorpus_iterable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_iterable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcorpus_file\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcorpus_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_vocab(corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, trim_rule\u001b[38;5;241m=\u001b[39mtrim_rule)\n\u001b[1;32m    430\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain(\n\u001b[1;32m    431\u001b[0m         corpus_iterable\u001b[38;5;241m=\u001b[39mcorpus_iterable, corpus_file\u001b[38;5;241m=\u001b[39mcorpus_file, total_examples\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_count,\n\u001b[1;32m    432\u001b[0m         total_words\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcorpus_total_words, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepochs, start_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha,\n\u001b[1;32m    433\u001b[0m         end_alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_alpha, compute_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss, callbacks\u001b[38;5;241m=\u001b[39mcallbacks)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/gensim/models/word2vec.py:1503\u001b[0m, in \u001b[0;36mWord2Vec._check_corpus_sanity\u001b[0;34m(self, corpus_iterable, corpus_file, passes)\u001b[0m\n\u001b[1;32m   1501\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParameter corpus_file must be a valid path to a file, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m corpus_file)\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(corpus_iterable, Iterable):\n\u001b[0;32m-> 1503\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe corpus_iterable must be an iterable of lists of strings, got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m corpus_iterable)\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m corpus_iterable \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(corpus_iterable, GeneratorType) \u001b[38;5;129;01mand\u001b[39;00m passes \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1506\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m   1507\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing a generator as corpus_iterable can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt support \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m passes. Try a re-iterable sequence.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: The corpus_iterable must be an iterable of lists of strings, got <class '__main__.reusable_sent.<locals>.MyIterable'> instead"
     ]
    }
   ],
   "source": [
    "model = Word2Vec(sentences=reusable_sent(), vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1fe0eb7-f9ca-4902-9d6c-7f56c4b4dee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
