{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n",
    "<a id='imports_id'> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T04:04:54.976207Z",
     "start_time": "2023-08-06T04:04:54.967241Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from dataclasses import dataclass, field\n",
    "from typing import TextIO, List\n",
    "from abc import ABC\n",
    "import pyarrow as pa\n",
    "from functools import cached_property\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T03:17:05.254987Z",
     "start_time": "2023-08-06T03:17:05.248524Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "PREFIX = 'sent'\n",
    "DATA_FOLDER = 'data'\n",
    "RAW_DATA = 'SentenceDatabase.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-04T15:06:07.388921Z",
     "start_time": "2023-08-04T15:06:07.385637Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class DatabaseParser(ABC):\n",
    "    dest: str\n",
    "    seq_per_csv: int = field(default=100000)\n",
    "\n",
    "\n",
    "    @cached_property\n",
    "    def table_schema(self) -> pa.Schema:\n",
    "        list_str_type = pa.list_(pa.string())\n",
    "        table_schema = pa.schema([\n",
    "            pa.field('init_words', list_str_type),\n",
    "            pa.field('mod_words', list_str_type),\n",
    "            pa.field('pos_tags', list_str_type)])\n",
    "        return table_schema\n",
    "\n",
    "    def __parse_word(self, line: str) -> List[str]:\n",
    "        return line.split()[1:]  # discard word index\n",
    "\n",
    "    def __read_sentence(self, database: TextIO) -> pa.Table:\n",
    "        init_words = []\n",
    "        mod_words = []\n",
    "        pos_tags = []\n",
    "\n",
    "        for i, line in enumerate(database):\n",
    "            if line == \"\":\n",
    "                raise EOFError\n",
    "            if not line[0].isnumeric():\n",
    "                break\n",
    "            init_word, mod_word, pos_tag = self.__parse_word(line)\n",
    "            init_words.append(init_word)\n",
    "            mod_words.append(mod_word)\n",
    "            pos_tags.append(pos_tag)\n",
    "\n",
    "        return pa.Table.from_arrays([[init_words], [mod_words], [pos_tags]], schema=self.table_schema)\n",
    "\n",
    "    def parse(self, database: TextIO) -> None:\n",
    "        sentences = []\n",
    "        curr: int = 0\n",
    "        part: int = 1\n",
    "        while True:\n",
    "            try:\n",
    "                curr_sent = self.__read_sentence(database)\n",
    "            except EOFError:\n",
    "                break\n",
    "            curr += 1\n",
    "            if curr == self.seq_per_csv:\n",
    "                pa.concat_tables(sentences).to_pandas(types_mapper=pd.ArrowDtype).to_orc(os.path.join(self.dest, f'{PREFIX}_{part}.orc'))\n",
    "                sentences = [curr_sent]\n",
    "                curr = 0\n",
    "                part += 1\n",
    "            else:\n",
    "                sentences.append(curr_sent)\n",
    "\n",
    "\n",
    "        sentences.to_pandas(types_mapper=pd.ArrowDtype).to_orc(os.path.join(self.dest, f'{PREFIX}_{part}.orc'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-08-04T15:06:08.950637Z"
    },
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, RAW_DATA), 'r') as f:\n",
    "   DatabaseParser(DATA_FOLDER, 1000000).parse(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T03:18:32.522037Z",
     "start_time": "2023-08-06T03:18:32.492238Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NUM_PARTS = 0\n",
    "\n",
    "for root, dirs, files in  os.walk(DATA_FOLDER):\n",
    "    NUM_PARTS += len([file for file in files if file.startswith(PREFIX)])\n",
    "\n",
    "NUM_PARTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T03:19:52.377791Z",
     "start_time": "2023-08-06T03:19:52.370076Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "def get_dataset(idx: int) -> pd.DataFrame:\n",
    "    return pd.read_orc(os.path.join(DATA_FOLDER, f'{PREFIX}_{idx}.orc'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Frequency Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "freq = Counter()\n",
    "for idx in range(1, NUM_PARTS + 1):\n",
    "    df = get_dataset(idx)\n",
    "    for word in df['mod_words'].explode():\n",
    "        freq[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, 'vocab', 'freq.json'), 'w') as f:\n",
    "    json.dump(freq, f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freq. Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_scores = []\n",
    "for idx in range(1, NUM_PARTS + 1):\n",
    "    df = get_dataset(idx)\n",
    "    freq_scores.append(df.mod_words.apply(lambda l: sum([freq[word] for word in l]) / len(l) if len(l) > 0 else 0).quantile(0.02))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "382749.2299380481"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_freq_score = sum(freq_scores) / len(freq_scores)\n",
    "min_freq_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in range(1, NUM_PARTS + 1):\n",
    "    df = get_dataset(idx)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vocabulary Exctraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T03:24:52.201969Z",
     "start_time": "2023-08-06T03:21:34.477980Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "unique_words = set()\n",
    "for idx in range(1, NUM_PARTS + 1):\n",
    "    df = get_dataset(idx)\n",
    "    unique_words |= set(df['mod_words'].explode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T03:24:52.260334Z",
     "start_time": "2023-08-06T03:24:52.219776Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1836994"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-06T04:06:34.562488Z",
     "start_time": "2023-08-06T04:06:30.944730Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_FOLDER, 'vocab', 'words.json'), 'w') as f:\n",
    "    json.dump(list(unique_words), f, ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.2-0.m110",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.2-0:m110"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
