{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2684f70c-7663-4070-a107-e0c75d1a0265",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034634ac-f65e-4572-9e90-af072c073c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import NamedTuple, Dict, Set, List, TextIO\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f73d5027-e4f5-4eda-b51b-2a50a3d05870",
   "metadata": {},
   "source": [
    "# Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0020a644-7ae5-432e-98e1-21c1136bf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Word(NamedTuple):\n",
    "    word: str\n",
    "    word_mod: str\n",
    "    pos: str\n",
    "\n",
    "    \n",
    "@dataclass\n",
    "class WordsParser:\n",
    "    words: dict[str, Set[Word]] = field(default_factory=dict)\n",
    "    def reset(self) -> None:\n",
    "        self.words = {}\n",
    "        \n",
    "    def word(self, line: str):\n",
    "        try:\n",
    "            word = Word(*line.split('@'))\n",
    "            self.words[word.word].add(word.pos)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        except KeyError:\n",
    "            self.words[word.word] = {word.pos}\n",
    "    def div(self, line: str):\n",
    "        pass\n",
    "    \n",
    "    def feed(self, line: str):\n",
    "        if line == '<START>' or line == '<END>':\n",
    "            self.div(line)\n",
    "        else:\n",
    "            self.word(line)\n",
    "            \n",
    "    def build(self) -> dict[str, Set[Word]]:\n",
    "        return self.words\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8bfdf3-5292-4c93-b21b-29b5f0f8c68c",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = WordsParser()\n",
    "with open(os.path.join('pos', 'texts.txt'), 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        parser.feed(line[:-1])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129e7210-ed1d-4aff-8b60-5e726473f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = parser.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6ecad-d072-40ce-b681-b2df53212386",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e87810-3e3f-4144-856b-2e7510c45f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_pos_per_word = sum(len(pos) for pos in words.values()) / len(words)\n",
    "avg_pos_per_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51febb8-47ee-4a6b-8c6e-edbdc8c4a2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_multiple_pos = len([pos for pos in words.values() if len(pos) > 1])\n",
    "words_with_multiple_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260d9709-6243-4921-80f5-89863b27e07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Perc. of vocabulary with single POS: {(len(words) - words_with_multiple_pos) / len(words) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8702c5-d2f8-403c-b787-93275d4f5bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_pos = set(['N', 'V', 'Adv', 'A', 'Num', 'Pron', 'Cj', 'Interj', 'Pp', 'Punct'])\n",
    "junk_pos = set(['Foreign', 'Unknown', '>XCOMP', 'Symbol', 'Guess', '<MWE>', 'X', 'X=12', 'Zoom', 'VIDEO', 'R', 'Unrecognized', 'B', 'D', 'Z', 'Energia', 'Food', 'Energy', 'General'])\n",
    "mapping = {\"Nom\":\"N\", \"Dat\":\"N\", \"Gen\":\"N\", \"Erg\":\"N\", \"Voc\":\"N\", \"Inst\":\"N\", \"Foc\":\"Adv\", \"Att\": 'Adv', \"Pv\": \"V\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f606c5-d6ae-486d-895e-e788804b376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_with_multiple_pos = [pos for pos in [[pos for pos in poss if pos in main_pos] for poss in words.values()] if len(pos) > 1]\n",
    "words_with_multiple_pos = len(words_with_multiple_pos)\n",
    "words_with_multiple_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10889a60-702a-4cdc-9a35-af47de445fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Real perc. of vocabulary with single POS: {(len(words) - words_with_multiple_pos) / len(words) * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f2476e-148d-4a11-b83b-28dacd1a14f3",
   "metadata": {},
   "source": [
    "# Creating a Vocabulary "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045302f2-286f-480e-912d-57f9ba90f0f5",
   "metadata": {},
   "source": [
    "## Clear words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffc9e90-21a8-4012-9374-b9da1437ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = '…?!.,\"„“\\';:()`~_‘$%/\\\\=+*|”'\n",
    "dash = '-'\n",
    "georgian_alphabet = 'აბგდევზთიკლმნოპჟრსტუფქღყშჩცძწჭხჯჰ'\n",
    "numbers = '0123456789'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ce287d-c377-457e-9597-d0a3b983fd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contains_any(str1, str2):\n",
    "    return any(char in str1 for char in str2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd71af3a-9e75-40f7-84ae-c6053fbf3fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(words.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56190d87-12e5-4867-844e-4b1e688cbaa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word not contains any of the following: georgian letters, numbers or punctuations\n",
    "cond1_mal = set(word_df[word_df[0].str.contains(f'[^{georgian_alphabet}{numbers}{puncts}{dash}]')][0])  \n",
    "\n",
    "cond2_mal = set(word_df[word_df[0].str.contains(f'[{georgian_alphabet}{numbers}]') & word_df[0].str.contains(f'[{puncts}]')][0]) \n",
    "\n",
    "cond3_mal = set(word_df[(word_df[0].str.startswith('-') | word_df[0].str.endswith('-') | (word_df[0].str.count('-') > 1)) & (word_df[0].str.len() != 1)][0])\n",
    "\n",
    "cond4_mal = set(word_df[word_df[0].str.contains(f'[{georgian_alphabet}]') & word_df[0].str.contains(f'[{numbers}]') & ~word_df[0].str.contains(f'[{dash}]')][0])\n",
    "\n",
    "cond5_mal = set(word_df[~word_df[0].str.contains(f'[{georgian_alphabet}{numbers}]') & ~(word_df[0].str.contains(f'[{puncts}]') & (word_df[0].str.len() == 1))][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b916695d-fcfb-4a07-b0c3-cef1a2e9f6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "malformed_words = (cond1_mal | cond2_mal | cond3_mal | cond4_mal | cond5_mal)\n",
    "print(f'Number of malformed words: {len(malformed_words)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbd0af-6fb3-4ab6-8025-6e5007cfa9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_set = words.keys() - malformed_words\n",
    "# remove malformed words from dict\n",
    "words = {word: pos for word, pos in words.items() if word in word_set}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75a7827-c8f2-4557-a18a-f8281e647651",
   "metadata": {},
   "source": [
    "## Clear POS Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb050cf-1332-49ed-80ae-6863b7baf983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map auxilary pos tags to main pos tags and remove junk\n",
    "words = {word: set([p if p not in mapping else mapping[p] for p in pos if p not in junk_pos]) for word, pos in words.items()}\n",
    "# assign \"Other\" to non-major POS tag types\n",
    "words = {word: set(['Other' if p not in main_pos else p for p in pos]) for word, pos in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfc6593-2940-48b2-915c-aacf7e41d50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove \"Other\" tag from set if there is already a main pos tag present\n",
    "words = {word: set([p for p in pos if len(pos) == 1 or p != 'Other']) for word, pos in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b847de-dd89-446c-90af-d00cf402929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get frequency data. in other words words and their most frequent pos tags\n",
    "by_freq_df = pd.read_csv(os.path.join('data', 'data.csv'))\n",
    "by_freq_df = by_freq_df[['word', 'pos_tag']].set_index('word')\n",
    "by_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9b87fe-8710-49a0-8641-18eb96b25e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign pos: \"Num\" to every word that contains a number\n",
    "words = {word: set(['Num']) if contains_any(word, numbers) else pos for word, pos in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae07d97-fde3-4f04-9ad0-1e1066f396f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for words with ambigious pos tags assign pos tag from dataframe\n",
    "words = {word: set([by_freq_df.loc[word].pos_tag]) if len(pos) != 1 and word in by_freq_df.index and by_freq_df.loc[word].pos_tag in main_pos else pos for word, pos in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bbd5e2-0656-4e6a-8706-0afc9c782216",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = {word: list(pos)[0] if len(pos) >= 1 else 'Other' for word, pos in words.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca9ed42-947e-4cba-aa59-6773af0897a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TAGS = set(words.values())\n",
    "print(f'POS tags: {POS_TAGS}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba3c30b-8114-4a7c-a83b-dc8c03fbd3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Word:\n",
    "    word: str\n",
    "    word_mod: str\n",
    "    pos: str\n",
    "\n",
    "    \n",
    "@dataclass\n",
    "class Sentence:\n",
    "    words: List[Word] = field(default_factory=list)\n",
    "    \n",
    "    def write(self, dest: TextIO):\n",
    "        for idx, word in enumerate(self.words):\n",
    "            dest.write(f'{idx}\\t{word.word}\\t{word.word_mod}\\t{word.pos}\\n')\n",
    "        dest.write('\\n')\n",
    "            \n",
    "        \n",
    "    \n",
    "@dataclass\n",
    "class SentenceParser:\n",
    "    source: TextIO\n",
    "    dest: TextIO\n",
    "    vocab: Set[str]\n",
    "    word_to_pos: Dict[str, str]\n",
    "    pos_set: Set[str]\n",
    "    curr_sentence: Sentence = field(default_factory=Sentence)\n",
    "        \n",
    "    def __word(self, line: str) -> None:\n",
    "        try:\n",
    "            word = Word(*line.split('@'))\n",
    "            try:\n",
    "                last_word = self.curr_sentence.words[-1]\n",
    "                if (last_word.word == '.' or last_word.word == '?' or last_word.word == '!') \\\n",
    "                and not (word.word == '.' or word.word == '?' or word.word == '!'):\n",
    "                    self.__end_sentence()\n",
    "            except IndexError:\n",
    "                pass\n",
    "            self.curr_sentence.words.append(word)\n",
    "        except TypeError:\n",
    "            # TODO: Mark sentence as malformed\n",
    "            pass\n",
    "        \n",
    "    def __div(self, line: str) -> None:\n",
    "        pass\n",
    "    \n",
    "    def __check_sentence(self) -> bool:\n",
    "        for word in self.curr_sentence.words:\n",
    "            if word.word_mod not in self.vocab:\n",
    "                # print(word.word_mod)\n",
    "                return False  # we shouldn't save sentences with malformed words\n",
    "            if word.pos not in self.pos_set:\n",
    "                word.pos = self.word_to_pos[word.word_mod]\n",
    "        return True\n",
    "    \n",
    "    def __end_sentence(self) -> None:\n",
    "        if self.__check_sentence(): # we save a sentence only when it contains no malformed words\n",
    "            self.curr_sentence.write(self.dest)\n",
    "        self.curr_sentence = Sentence()\n",
    "    \n",
    "    def __feed(self, line: str) -> None:\n",
    "        if line == '<START>' or line == '<END>':\n",
    "            return self.__div(line)\n",
    "        else:\n",
    "            return self.__word(line)\n",
    "            \n",
    "    def run(self) -> None:\n",
    "        for i, line in enumerate(self.source):\n",
    "            self.__feed(line.strip())\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d43ad92-8b4a-4fa0-b3f3-4de57b9f30c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join('pos', 'texts.txt'), 'r') as src:\n",
    "    with open(os.path.join('data', 'SentenceDatabase.txt'), 'w') as dest:\n",
    "        parser = SentenceParser(src, dest, set(words.keys()) , words, set(POS_TAGS))\n",
    "        parser.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75757e-aca3-44fd-aadc-a3e98dcebdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "[1, 2, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9eb465-5e65-4405-87b3-f30def544d9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
