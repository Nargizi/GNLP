{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:52:58.046599Z",
     "start_time": "2023-07-18T10:52:55.346683Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from typing import Optional, Sequence, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import itertools\n",
    "\n",
    "from nltk.metrics import distance\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:52:58.051039Z",
     "start_time": "2023-07-18T10:52:58.049124Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:00.645902Z",
     "start_time": "2023-07-18T10:52:58.052483Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos_tag</th>\n",
       "      <th>freq</th>\n",
       "      <th>word_length</th>\n",
       "      <th>lemma_length</th>\n",
       "      <th>ratio</th>\n",
       "      <th>lemma_length_category</th>\n",
       "      <th>word_length_category</th>\n",
       "      <th>ratio_category</th>\n",
       "      <th>reported_speech</th>\n",
       "      <th>freq_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1104841</td>\n",
       "      <td>მონოზონისა</td>\n",
       "      <td>მონოზონი</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>medium</td>\n",
       "      <td>medium</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1260770</td>\n",
       "      <td>სამხრეთიდგან</td>\n",
       "      <td>სამხრეთი</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>637615</td>\n",
       "      <td>მოფიქრებაშია</td>\n",
       "      <td>მოფიქრება</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79017</td>\n",
       "      <td>სიდიადეს</td>\n",
       "      <td>სიდიადე</td>\n",
       "      <td>N</td>\n",
       "      <td>209</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>1.142857</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1107010</td>\n",
       "      <td>განგსტერებისათვის</td>\n",
       "      <td>განგსტერი</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>9</td>\n",
       "      <td>1.888889</td>\n",
       "      <td>medium</td>\n",
       "      <td>high</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956889</th>\n",
       "      <td>485527</td>\n",
       "      <td>ტონგას</td>\n",
       "      <td>ტონგა</td>\n",
       "      <td>N</td>\n",
       "      <td>102</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956890</th>\n",
       "      <td>113442</td>\n",
       "      <td>ადენა</td>\n",
       "      <td>ადენა</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>equal</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956891</th>\n",
       "      <td>131905</td>\n",
       "      <td>ვრაცხ</td>\n",
       "      <td>*რაცხვა</td>\n",
       "      <td>V</td>\n",
       "      <td>46</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>low</td>\n",
       "      <td>low</td>\n",
       "      <td>less</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956892</th>\n",
       "      <td>1049224</td>\n",
       "      <td>ამოდგომაც</td>\n",
       "      <td>ამოდგომა</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1.125000</td>\n",
       "      <td>medium</td>\n",
       "      <td>low</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>956893</th>\n",
       "      <td>652185</td>\n",
       "      <td>ცხიმისაგან</td>\n",
       "      <td>ცხიმი</td>\n",
       "      <td>N</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>low</td>\n",
       "      <td>medium</td>\n",
       "      <td>greater</td>\n",
       "      <td>False</td>\n",
       "      <td>medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>956894 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0               word      lemma pos_tag  freq  word_length  \\\n",
       "0          1104841         მონოზონისა   მონოზონი       N     1           10   \n",
       "1          1260770       სამხრეთიდგან   სამხრეთი       N     1           12   \n",
       "2           637615       მოფიქრებაშია  მოფიქრება       N     1           12   \n",
       "3            79017           სიდიადეს    სიდიადე       N   209            8   \n",
       "4          1107010  განგსტერებისათვის  განგსტერი       N     2           17   \n",
       "...            ...                ...        ...     ...   ...          ...   \n",
       "956889      485527             ტონგას      ტონგა       N   102            6   \n",
       "956890      113442              ადენა      ადენა       N     5            5   \n",
       "956891      131905              ვრაცხ    *რაცხვა       V    46            5   \n",
       "956892     1049224          ამოდგომაც   ამოდგომა       N     1            9   \n",
       "956893      652185         ცხიმისაგან      ცხიმი       N     8           10   \n",
       "\n",
       "        lemma_length     ratio lemma_length_category word_length_category  \\\n",
       "0                  8  1.250000                medium               medium   \n",
       "1                  8  1.500000                medium                 high   \n",
       "2                  9  1.333333                medium                 high   \n",
       "3                  7  1.142857                   low                  low   \n",
       "4                  9  1.888889                medium                 high   \n",
       "...              ...       ...                   ...                  ...   \n",
       "956889             5  1.200000                   low                  low   \n",
       "956890             5  1.000000                   low                  low   \n",
       "956891             7  0.714286                   low                  low   \n",
       "956892             8  1.125000                medium                  low   \n",
       "956893             5  2.000000                   low               medium   \n",
       "\n",
       "       ratio_category  reported_speech freq_category  \n",
       "0             greater            False           low  \n",
       "1             greater            False           low  \n",
       "2             greater            False           low  \n",
       "3             greater            False          high  \n",
       "4             greater            False           low  \n",
       "...               ...              ...           ...  \n",
       "956889        greater            False          high  \n",
       "956890          equal            False        medium  \n",
       "956891           less            False        medium  \n",
       "956892        greater            False           low  \n",
       "956893        greater            False        medium  \n",
       "\n",
       "[956894 rows x 13 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('csv/train.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('მონოზონისა', 'მონოზონი')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word, lemma = data.iloc[0]['word'], data.iloc[0]['lemma']\n",
    "word, lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0), (1, 1), (2, 2), (2, 3), (2, 4), (2, 5)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distance.edit_distance_align('ეს', 'ესეთი')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m data \u001B[38;5;241m=\u001B[39m data[[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mword\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlemma\u001B[39m\u001B[38;5;124m'\u001B[39m]]\n\u001B[0;32m----> 2\u001B[0m data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124medit_distance\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43;01mlambda\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mdistance\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medit_distance\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mword\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlemma\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/frame.py:9423\u001B[0m, in \u001B[0;36mDataFrame.apply\u001B[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001B[0m\n\u001B[1;32m   9412\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapply\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m frame_apply\n\u001B[1;32m   9414\u001B[0m op \u001B[38;5;241m=\u001B[39m frame_apply(\n\u001B[1;32m   9415\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   9416\u001B[0m     func\u001B[38;5;241m=\u001B[39mfunc,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   9421\u001B[0m     kwargs\u001B[38;5;241m=\u001B[39mkwargs,\n\u001B[1;32m   9422\u001B[0m )\n\u001B[0;32m-> 9423\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mop\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39m__finalize__(\u001B[38;5;28mself\u001B[39m, method\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mapply\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/apply.py:678\u001B[0m, in \u001B[0;36mFrameApply.apply\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    675\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw:\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mapply_raw()\n\u001B[0;32m--> 678\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_standard\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/apply.py:798\u001B[0m, in \u001B[0;36mFrameApply.apply_standard\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    797\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mapply_standard\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 798\u001B[0m     results, res_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapply_series_generator\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    800\u001B[0m     \u001B[38;5;66;03m# wrap results\u001B[39;00m\n\u001B[1;32m    801\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwrap_results(results, res_index)\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/apply.py:812\u001B[0m, in \u001B[0;36mFrameApply.apply_series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    809\u001B[0m results \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m    811\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m option_context(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.chained_assignment\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m--> 812\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, v \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(series_gen):\n\u001B[1;32m    813\u001B[0m         \u001B[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001B[39;00m\n\u001B[1;32m    814\u001B[0m         results[i] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mf(v)\n\u001B[1;32m    815\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(results[i], ABCSeries):\n\u001B[1;32m    816\u001B[0m             \u001B[38;5;66;03m# If we have a view on v, we need to make a copy because\u001B[39;00m\n\u001B[1;32m    817\u001B[0m             \u001B[38;5;66;03m#  series_generator will swap out the underlying data\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/apply.py:940\u001B[0m, in \u001B[0;36mFrameColumnApply.series_generator\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    937\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m arr, name \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mzip\u001B[39m(values, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindex):\n\u001B[1;32m    938\u001B[0m     \u001B[38;5;66;03m# GH#35462 re-pin mgr in case setitem changed it\u001B[39;00m\n\u001B[1;32m    939\u001B[0m     ser\u001B[38;5;241m.\u001B[39m_mgr \u001B[38;5;241m=\u001B[39m mgr\n\u001B[0;32m--> 940\u001B[0m     \u001B[43mmgr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mset_values\u001B[49m\u001B[43m(\u001B[49m\u001B[43marr\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    941\u001B[0m     \u001B[38;5;28mobject\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__setattr__\u001B[39m(ser, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_name\u001B[39m\u001B[38;5;124m\"\u001B[39m, name)\n\u001B[1;32m    942\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m ser\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/pandas/core/internals/managers.py:2074\u001B[0m, in \u001B[0;36mSingleBlockManager.set_values\u001B[0;34m(self, values)\u001B[0m\n\u001B[1;32m   2070\u001B[0m \u001B[38;5;66;03m# TODO(CoW) do we need to handle copy on write here? Currently this is\u001B[39;00m\n\u001B[1;32m   2071\u001B[0m \u001B[38;5;66;03m# only used for FrameColumnApply.series_generator (what if apply is\u001B[39;00m\n\u001B[1;32m   2072\u001B[0m \u001B[38;5;66;03m# mutating inplace?)\u001B[39;00m\n\u001B[1;32m   2073\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mvalues \u001B[38;5;241m=\u001B[39m values\n\u001B[0;32m-> 2074\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mblocks[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39m_mgr_locs \u001B[38;5;241m=\u001B[39m BlockPlacement(\u001B[38;5;28mslice\u001B[39m(\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m)\u001B[49m))\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "data = data[['word', 'lemma']]\n",
    "data['edit_distance'] = data.apply(lambda x: distance.edit_distance(x.word, x.lemma), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='edit_distance', ylabel='count'>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(data, x ='edit_distance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:01.226549Z",
     "start_time": "2023-07-18T10:53:00.715985Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH: int = int(max(data.lemma.str.len().max(), data.word.str.len().max()))\n",
    "MAX_LENGTH += 1 # add one for <end> token\n",
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_tokens(t):\n",
    "    yield from list(t)\n",
    "\n",
    "UNK_TOKEN = '<unk>'\n",
    "EOW_TOKEN = '<end>'\n",
    "PAD_TOKEN = '<pad>'\n",
    "SOW_TOKEN = '<start>'\n",
    "\n",
    "vocab = build_vocab_from_iterator(iterator=get_tokens(itertools.chain(data['word'], data['lemma'])),\n",
    "                                  specials=[EOW_TOKEN, UNK_TOKEN, PAD_TOKEN, SOW_TOKEN],\n",
    "                                  special_first=False\n",
    "                                  )\n",
    "vocab.set_default_index(vocab[UNK_TOKEN])\n",
    "\n",
    "def word_to_seq(word: str):\n",
    "    return torch.tensor(vocab(list(word)) + [vocab[EOW_TOKEN]])"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:04.890081Z",
     "start_time": "2023-07-18T10:53:04.888308Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:04.895573Z",
     "start_time": "2023-07-18T10:53:04.893598Z"
    }
   },
   "outputs": [],
   "source": [
    "class LemmaDataSet(Dataset):\n",
    "    def __init__(self, data_frame: pd.DataFrame):\n",
    "        self.data = data_frame\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> (str, str):\n",
    "        row = self.data.iloc[idx]\n",
    "        return row['word'], row['lemma']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:04.899832Z",
     "start_time": "2023-07-18T10:53:04.898236Z"
    }
   },
   "outputs": [],
   "source": [
    "def coallate_words(batch):\n",
    "    word_list, lemma_list = [torch.zeros(MAX_LENGTH, dtype=torch.int64)], [torch.zeros(MAX_LENGTH, dtype=torch.int64)]\n",
    "    for word, lemma in batch:\n",
    "        word_list.append(word_to_seq(word))\n",
    "        lemma_list.append(word_to_seq(lemma))\n",
    "\n",
    "\n",
    "    return pad_sequence(word_list, batch_first=True, padding_value=vocab[PAD_TOKEN])[1:], pad_sequence(lemma_list, batch_first=True, padding_value=vocab[PAD_TOKEN])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.103Z",
     "start_time": "2023-07-18T10:53:04.903645Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data, val_data = train_test_split(data, random_state=RANDOM_STATE, train_size=0.8, shuffle=True)\n",
    "train_loader = DataLoader(LemmaDataSet(train_data), batch_size=BATCH_SIZE, shuffle=True, collate_fn=coallate_words, pin_memory=True)\n",
    "val_loader = DataLoader(LemmaDataSet(val_data), batch_size=BATCH_SIZE, shuffle=True, collate_fn=coallate_words, pin_memory=True)\n",
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.109911Z",
     "start_time": "2023-07-18T10:53:05.108424Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_dim: int, emb_dim: int,  hidden_dim: int, num_layers: int =1):\n",
    "        super().__init__()\n",
    "\n",
    "        # set dimensions\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.embedding_size = emb_dim\n",
    "        self.vocab_size = vocab_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # initialize layers\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_size)\n",
    "        self.gru = nn.GRU(self.embedding_size, self.hidden_size, num_layers=self.num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, hidden: Optional[torch.Tensor] = None):\n",
    "        embedded = self.embedding(input)\n",
    "        if hidden is not None:\n",
    "            output, hidden = self.gru(embedded, hidden)\n",
    "        else:\n",
    "            output, hidden = self.gru(embedded)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.115698Z",
     "start_time": "2023-07-18T10:53:05.113926Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, emb_dim: int, hidden_dim: int, vocab_dim: int, num_layers: int = 1):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        # set dimensions\n",
    "        self.hidden_size = hidden_dim\n",
    "        self.embedding_size = emb_dim\n",
    "        self.output_size = vocab_dim\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        #initialize layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.gru = nn.GRU(self.hidden_size,self.hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "\n",
    "    def forward(self, input: torch.Tensor, hidden: torch.Tensor):\n",
    "        embedding = F.relu(self.embedding(input))\n",
    "        output, hidden = self.gru(embedding, hidden)\n",
    "        pred = self.softmax(self.out(output))\n",
    "        return pred, hidden\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.136833Z",
     "start_time": "2023-07-18T10:53:05.122130Z"
    }
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder: nn.Module, decoder: nn.Module, sow_token: int, \n",
    "                 max_length: int, device: str='cpu'):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "#         self.decoder.embedding = self.encoder.embedding  # \n",
    "        self.sow_token = sow_token\n",
    "        self.length = max_length\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source: torch.Tensor, target: Optional[torch.Tensor] = None, teacher_forcing_ratio: float =0.5):\n",
    "        input_length = source.size(1) \n",
    "        batch_size = source.size(0)\n",
    "        vocab_size = self.encoder.vocab_size\n",
    "\n",
    "        #initialize a variable to hold the predicted outputs\n",
    "        outputs = []\n",
    "        encoder_output, encoder_hidden = self.encoder(source[:, 0].unsqueeze(1))\n",
    "        #encode every word in a sentence\n",
    "        for i in range(1, input_length):\n",
    "            encoder_output, encoder_hidden = self.encoder(source[:, i].unsqueeze(1), encoder_hidden)\n",
    "\n",
    "        #use the encoder’s hidden layer as the decoder hidden\n",
    "        decoder_hidden = encoder_hidden.to(self.device)\n",
    "\n",
    "        #add a start_of_the_word token before the first predicted word\n",
    "        decoder_input = torch.empty(batch_size, 1, dtype=torch.long, device=self.device).fill_(self.sow_token)\n",
    "        \n",
    "        # max_length: int = self.length\n",
    "        for t in range(self.length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden)\n",
    "            outputs.append(decoder_output)\n",
    "            _, topi = decoder_output.topk(1)\n",
    "            if target is not None and target.size(1) > t:\n",
    "                teacher_force: bool = random.random() < self.teacher_forcing_ratio\n",
    "                target_input = target[:, t].unsqueeze(1)\n",
    "                decoder_input = (target_input if teacher_force else topi.squeeze(-1).detach())\n",
    "            else:\n",
    "                decoder_input = topi.squeeze(-1).detach()\n",
    "        return torch.cat(outputs, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.304314Z",
     "start_time": "2023-07-18T10:53:05.126750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Parameters: 57447\n"
     ]
    }
   ],
   "source": [
    "MODEL_VERSION = 0\n",
    "model = Seq2Seq(EncoderRNN(vocab_dim=len(vocab), emb_dim=64 ,hidden_dim=64).to(device), DecoderRNN(vocab_dim=len(vocab), emb_dim=64, hidden_dim=64).to(device), sow_token=vocab[SOW_TOKEN], max_length=MAX_LENGTH, device=device)\n",
    "model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "model_scripted.save(f'models/base_model_v{MODEL_VERSION}.pt') \n",
    "print(f'Number of Parameters: {sum(p.numel() for p in model.parameters())}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:05.309292Z",
     "start_time": "2023-07-18T10:53:05.307308Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def train_epoch(dataloader, model, optimizer, criterion):\n",
    "    model.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        decoder_outputs = model(input_tensor, target_tensor)\n",
    "        \n",
    "        try:\n",
    "        \n",
    "            loss = criterion(\n",
    "                decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "                target_tensor.view(-1)\n",
    "            )\n",
    "        except ValueError:\n",
    "            print(decoder_outputs.size(), target_tensor.size())\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def validate_epoch(dataloader, model, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "        input_tensor = input_tensor.to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        \n",
    "        decoder_outputs = model(input_tensor)\n",
    "        \n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        total_loss += loss.item() \n",
    "        \n",
    "    return total_loss / len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:21.971337Z",
     "start_time": "2023-07-18T10:53:21.969028Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "def train(train_loader, val_loader,  model, n_epochs, learning_rate=0.001,\n",
    "          display_every=10):\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    iter_train_loss = 0\n",
    "    iter_val_loss = 0\n",
    "    plot_train_loss = []\n",
    "    plot_val_loss = []\n",
    "\n",
    "    start = datetime.now()\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        train_loss = train_epoch(train_loader, model, optimizer, criterion)\n",
    "        val_loss = validate_epoch(val_loader, model, criterion)\n",
    "        iter_train_loss += train_loss\n",
    "        iter_val_loss += val_loss\n",
    "        \n",
    "        if epoch % display_every == 0:\n",
    "            train_avg = iter_train_loss / display_every\n",
    "            train_total = iter_train_loss\n",
    "            val_avg = iter_val_loss / display_every\n",
    "            val_total = iter_val_loss\n",
    "            plot_train_loss.append(train_avg)\n",
    "            iter_train_loss = 0\n",
    "            plot_val_loss.append(val_avg)\n",
    "            iter_val_loss = 0\n",
    "            \n",
    "            print(f'Epoch: {epoch}: Train Loss: {train_total}, Validation Loss: {val_total},\\\n",
    "            Train AVG Loss: {train_avg}, Validation AVG Loss: {val_avg},\\\n",
    "            Time Elapsed: {(datetime.now() - start).total_seconds() / 60}M')\n",
    "            start = datetime.now()\n",
    "    \n",
    "    return model, plot_val_loss, plot_train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "VERSION = 2\n",
    "WEIGHT_PATH = 'Lemmatization/weights/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:21.978794Z",
     "start_time": "2023-07-18T10:53:21.974010Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[83], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m VERSION \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m\n\u001B[1;32m      2\u001B[0m model\u001B[38;5;241m.\u001B[39mload_state_dict(torch\u001B[38;5;241m.\u001B[39mload( \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLemmatization/weights/base_model_v\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[0;32m----> 3\u001B[0m model,graph_val, graph_train,  \u001B[38;5;241m=\u001B[39m \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlearning_rate\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m torch\u001B[38;5;241m.\u001B[39msave(model\u001B[38;5;241m.\u001B[39mstate_dict(), \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mLemmatization/weights/base_model_v\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mVERSION\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.pt\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[0;32mIn[66], line 18\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(train_loader, val_loader, model, n_epochs, learning_rate, display_every)\u001B[0m\n\u001B[1;32m     16\u001B[0m start \u001B[38;5;241m=\u001B[39m datetime\u001B[38;5;241m.\u001B[39mnow()\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m, n_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[0;32m---> 18\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcriterion\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m     val_loss \u001B[38;5;241m=\u001B[39m validate_epoch(val_loader, model, criterion)\n\u001B[1;32m     20\u001B[0m     iter_train_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m train_loss\n",
      "Cell \u001B[0;32mIn[65], line 22\u001B[0m, in \u001B[0;36mtrain_epoch\u001B[0;34m(dataloader, model, optimizer, criterion)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m:\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;28mprint\u001B[39m(decoder_outputs\u001B[38;5;241m.\u001B[39msize(), target_tensor\u001B[38;5;241m.\u001B[39msize())\n\u001B[0;32m---> 22\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     24\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     26\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/_tensor.py:487\u001B[0m, in \u001B[0;36mTensor.backward\u001B[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[1;32m    477\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    478\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[1;32m    479\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[1;32m    480\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    485\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[1;32m    486\u001B[0m     )\n\u001B[0;32m--> 487\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    488\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[1;32m    489\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/envs/pytorch/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001B[0m, in \u001B[0;36mbackward\u001B[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[1;32m    195\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[1;32m    197\u001B[0m \u001B[38;5;66;03m# The reason we repeat same the comment below is that\u001B[39;00m\n\u001B[1;32m    198\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[1;32m    199\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[0;32m--> 200\u001B[0m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[1;32m    201\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    202\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(WEIGHT_PATH, f'base_model_v{VERSION - 1}.pt')))\n",
    "model,graph_val, graph_train,  = train(train_loader, val_loader, model.to(device), 100, learning_rate=0.001)\n",
    "torch.save(model.state_dict(), os.path.join(WEIGHT_PATH, f'base_model_v{VERSION - 1}.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(graph_train, label='Train')\n",
    "sns.lineplot(graph_val, label='Validation')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Avg. Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-07-18T10:53:21.980400Z",
     "start_time": "2023-07-18T10:53:21.977128Z"
    }
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(WEIGHT_PATH, f'base_model_v{VERSION}.pt')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_to_words(t):\n",
    "    return [''.join([vocab.get_itos()[i] for i in word[:list(word).index(vocab[EOW_TOKEN])]]) for word in t]\n",
    "    # list(word).index(vocab[EOW_TOKEN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7234127046332147\n"
     ]
    }
   ],
   "source": [
    "total = 0\n",
    "correct = 0\n",
    "for source, target in val_loader:\n",
    "    pred = model(source.to(device), target.to(device)).argmax(dim=2)\n",
    "    for t, p in zip(target, pred):\n",
    "        total += 1\n",
    "        if all(t == p):\n",
    "            correct += 1\n",
    "print(correct / total)\n",
    "# source, target = next(iter(train_loader))\n",
    "# pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ბ',\n",
       " 'ა',\n",
       " 'ზ',\n",
       " 'ი',\n",
       " 'ლ',\n",
       " 'ი',\n",
       " 'კ',\n",
       " 'ე',\n",
       " 'ბ',\n",
       " 'შ',\n",
       " 'ი',\n",
       " 'ც',\n",
       " '<end>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.get_itos()[i] for i in source[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ბ',\n",
       " 'ა',\n",
       " 'ზ',\n",
       " 'ი',\n",
       " 'ლ',\n",
       " 'ი',\n",
       " 'კ',\n",
       " 'ა',\n",
       " '<end>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.get_itos()[i] for i in pred[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ბ',\n",
       " 'ა',\n",
       " 'ზ',\n",
       " 'ი',\n",
       " 'ლ',\n",
       " 'ი',\n",
       " 'კ',\n",
       " 'ა',\n",
       " '<end>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>',\n",
       " '<pad>']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.get_itos()[i] for i in target[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.get_itos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 2]),\n",
       " tensor([[ 0.8605, -0.8043,  0.9290,  0.2762,  1.3111],\n",
       "         [-1.5824, -0.3551,  0.5694, -0.5948, -0.9864],\n",
       "         [-0.2881, -0.2128,  0.2438, -1.0952, -0.5630]], requires_grad=True))"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-pytorch-pytorch",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "PyTorch 1-13",
   "language": "python",
   "name": "conda-env-pytorch-pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
