{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed13c089-1b46-4a62-a594-a3e17428c3eb",
   "metadata": {},
   "source": [
    "სულ 216723326 ხაზია, ~44გბ ფაილი\n",
    "\n",
    "კორპუსის გაპარსვა გვიწევს აქ, უკეთესი გზა არ ვიცი, თავისი პარსერი ექნება პაულს მარა მეეჭვება მაგის გამოყენება გამოვიდეს\n",
    "\n",
    "ხაზებად შეგიძლია წაიკითხო და მერე სასურველი ინფორმაცია ამოიღო თითო ხაზიდან (ზოგ ხაზზე სიტყვის ინფო არცაა)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbe8a6b6-b10d-4811-92f4-77427750a091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "('<document file=\"lib-ge/texts/00069\" author=\"სავიონ ლიბრეხტი\" title=\"როხელეს '\n",
      " 'უნაკლო საქმრო\" translator=\"თეა ასიაშვილი\">\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\t'\n",
      " 'როხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "1\n",
      "'<text>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "2\n",
      "'<title>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "3\n",
      "('როხელეს\\tროხელეს\\t¦როხელე¦\\t¦როხელე¦\\t¦ N Prop Anthr FirstName Gen ¦\\t'\n",
      " 'lib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "4\n",
      "('უნაკლო\\tუნაკლო\\t¦უნაკლო¦\\t¦უნაკლო¦\\t¦ A Gen Att ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\t'\n",
      " 'როხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "5\n",
      "('საქმრო\\tსაქმრო\\t¦საქმრო¦\\t¦საქმრო/ქმრ¦\\t¦ A Part FutPart Gen Att ¦\\tlib.ge\\t'\n",
      " 'სავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "6\n",
      "'</title>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "7\n",
      "'<div>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "8\n",
      "'<p>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "9\n",
      "('ამ\\tამ\\t¦ეს¦\\t¦ეს¦\\t¦ Pron Dem Gen ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს '\n",
      " 'უნაკლო საქმრო\\t\\t\\n')\n",
      "10\n",
      "('ზამთრის\\tზამთრის\\t¦ზამთარ·ი¦\\t¦ზამთ[ა]რ·ი¦\\t¦ N Temp Gen Sg ¦\\tlib.ge\\t'\n",
      " 'სავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "11\n",
      "('მიწურულს\\tმიწურულს\\t¦მი·წურულ·ი¦\\t¦მი·წურულ·ი/წურ¦\\t¦ A Part PastPart Pv Dat '\n",
      " 'Sg ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "12\n",
      "('თითქმის\\tთითქმის\\t¦თითქმის¦\\t¦თითქმის¦\\t¦ Adv Deg ¦\\tlib.ge\\tსავიონ '\n",
      " 'ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "13\n",
      "('სასოწარკვეთილი\\tსასოწარკვეთილი\\t¦სასოწარკვეთილ·ი¦\\t¦სასოწარკვეთილ·ი¦\\t¦ A '\n",
      " 'Nom Sg ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "14\n",
      "('გახლდით\\tგახლდით\\t¦ხლება¦\\t¦ხლებ[ა]/ხლ¦ხლებ[ა]/ახლ¦\\t¦ V MedPass Impf <S-IO> '\n",
      " '<S:Nom> <IO:Dat> S:1Sg IO:2Pl ¦ V MedPass Impf <S-IO> <S:Nom> <IO:Dat> S:1Pl '\n",
      " 'IO:2 ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "15\n",
      "('–\\t–\\t¦–¦\\t¦–¦\\t¦ Punct Dash ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო '\n",
      " 'საქმრო\\t\\t\\n')\n",
      "16\n",
      "('რა\\tრა\\t¦რა¦\\t¦რ[ა]¦\\t¦ Pron Int Nonhum Nom Att ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\t'\n",
      " 'როხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "17\n",
      "('ხანია\\tხანია\\t¦ხან·ი¦\\t¦ხან·ი¦ხ[ა]ნ·ი¦\\t¦ N Prop Top Place Nom Encl:Aux ¦ N '\n",
      " 'Nom Sg Encl:Aux ¦ N Hum Nom Sg Encl:Aux ¦ N Temp Nom Sg Encl:Aux ¦\\tlib.ge\\t'\n",
      " 'სავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "18\n",
      "(',\\t,\\t¦,¦\\t¦,¦\\t¦ Punct Comma ¦\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო '\n",
      " 'საქმრო\\t\\t\\n')\n",
      "19\n",
      "('ჩემი\\tჩემი\\t¦ჩემ·ი¦\\t¦ჩემ·ი¦\\t¦ Pron Poss Poss1Sg Gen Att ¦\\tlib.ge\\tსავიონ '\n",
      " 'ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n",
      "20\n",
      "('უფროსი\\tუფროსი\\t¦უფროს·ი¦\\t¦უფროს·ი¦\\t¦ N Hum Qual Gen Att ¦\\tlib.ge\\tსავიონ '\n",
      " 'ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n')\n"
     ]
    }
   ],
   "source": [
    "with open('grc-cwb') as f:\n",
    "    for number, line in enumerate(f):\n",
    "        pp.pprint(number)\n",
    "        pp.pprint(line)\n",
    "        if number == 20:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e47f43f-f144-4dae-9b74-327603158e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n",
      "'</p>\\t\\t\\t\\t\\tlib.ge\\tსავიონ ლიბრეხტი\\tროხელეს უნაკლო საქმრო\\t\\t\\n'\n",
      "start <Element 'document' at 0x7fc532a498f0>\n",
      "start <Element 'text' at 0x7fc532a49ef0>\n",
      "start <Element 'title' at 0x7fc532a3fcb0>\n",
      "end <Element 'title' at 0x7fc532a3fcb0>\n",
      "start <Element 'div' at 0x7fc532a3fd10>\n",
      "start <Element 'p' at 0x7fc532a3fe90>\n",
      "start <Element 'S-IO' at 0x7fc532a3fef0>\n",
      "start <Element 'S-Nom' at 0x7fc532a3fb90>\n",
      "start <Element 'IO-Dat' at 0x7fc532a3fc50>\n",
      "start <Element 'S-IO' at 0x7fc532a3f050>\n",
      "start <Element 'S-Nom' at 0x7fc532a3f1d0>\n",
      "start <Element 'IO-Dat' at 0x7fc532a3f350>\n",
      "start <Element 'S' at 0x7fc532a3f4d0>\n",
      "start <Element 'S-Nom' at 0x7fc532a3f650>\n",
      "start <Element 'S' at 0x7fc532a3f7d0>\n",
      "start <Element 'S-Nom' at 0x7fc532a3f950>\n",
      "start <Element 'S-DO' at 0x7fc532a3fad0>\n",
      "start <Element 'S-Erg' at 0x7fc532a3f9b0>\n",
      "start <Element 'DO-Nom' at 0x7fc532a3f170>\n",
      "start <Element 'S-DO-IO' at 0x7fc532a3f2f0>\n",
      "start <Element 'S-Erg' at 0x7fc532a3f470>\n",
      "start <Element 'DO-Nom' at 0x7fc532a3f5f0>\n",
      "start <Element 'IO-Dat' at 0x7fc532a3f770>\n",
      "start <Element 'S-IO' at 0x7fc532a3f8f0>\n",
      "start <Element 'S-Nom' at 0x7fc532a40e90>\n",
      "start <Element 'IO-Dat' at 0x7fc532a40d70>\n",
      "start <Element 'S-DO' at 0x7fc532a40050>\n",
      "start <Element 'S-Dat' at 0x7fc532a401d0>\n",
      "start <Element 'DO-Nom' at 0x7fc532a40350>\n",
      "start <Element 'S-DO' at 0x7fc532a404d0>\n",
      "start <Element 'S-Nom' at 0x7fc532a40650>\n",
      "start <Element 'DO-Dat' at 0x7fc532a407d0>\n"
     ]
    },
    {
     "ename": "ParseError",
     "evalue": "mismatched tag: line 57, column 2 (<string>)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/site-packages/IPython/core/interactiveshell.py\"\u001b[0m, line \u001b[1;32m3553\u001b[0m, in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \u001b[1;32m\"/var/tmp/ipykernel_2701/4237044835.py\"\u001b[0m, line \u001b[1;32m12\u001b[0m, in \u001b[1;35m<module>\u001b[0m\n    for event, elem in parser.read_events():\n",
      "  File \u001b[1;32m\"/opt/conda/lib/python3.7/xml/etree/ElementTree.py\"\u001b[0m, line \u001b[1;32m1297\u001b[0m, in \u001b[1;35mread_events\u001b[0m\n    raise event\n",
      "\u001b[0;36m  File \u001b[0;32m\"/opt/conda/lib/python3.7/xml/etree/ElementTree.py\"\u001b[0;36m, line \u001b[0;32m1269\u001b[0;36m, in \u001b[0;35mfeed\u001b[0;36m\u001b[0m\n\u001b[0;31m    self._parser.feed(data)\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m\"<string>\"\u001b[0;36m, line \u001b[0;32munknown\u001b[0m\n\u001b[0;31mParseError\u001b[0m\u001b[0;31m:\u001b[0m mismatched tag: line 57, column 2\n"
     ]
    }
   ],
   "source": [
    "# import xml.etree.ElementTree as ET\n",
    "# import re\n",
    "# parser = ET.XMLPullParser(['start', 'end'])\n",
    "# with open('grc-cwb') as f:\n",
    "#     for number, line in enumerate(f):\n",
    "#         line = re.sub(r'<(.+?)>', '&lt;\\\\1&gt;', line)\n",
    "#         parser.feed(line)\n",
    "#         if number == 56:\n",
    "#             pp.pprint(number)\n",
    "#             pp.pprint(line)\n",
    "#             break\n",
    "# for event, elem in parser.read_events():\n",
    "#     print(event, elem)            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f5d1836-ccaf-4e07-b7c8-6c7d5e1d8239",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from typing import List, Any\n",
    "import pprint\n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Word:\n",
    "    word_init: str\n",
    "    word_mod: str\n",
    "    lemma_basic: str\n",
    "    lemma_adv: str\n",
    "    title: str\n",
    "    pos_tags: List[str] = field(default_factory=list)\n",
    "    \n",
    "    \n",
    "    def reformat(self):\n",
    "        print(\"word1, word2, lemma1, lemma2, pos_tags\")\n",
    "        print(self.word_init, self.word_mod, self.lemma_basic, self.lemma_adv,self.pos_tags)\n",
    "    \n",
    "@dataclass\n",
    "class Line:\n",
    "    words: List[Word] = field(default_factory=list)\n",
    "    \n",
    "    def reformat(self):\n",
    "        print(\"LINE:\")\n",
    "        for word in self.words:\n",
    "            word.reformat()\n",
    "\n",
    "@dataclass\n",
    "class Text:\n",
    "    title: str = field(default=\"\")\n",
    "    lines: List[Line] = field(default_factory=list)\n",
    "    \n",
    "    def reformat(self):\n",
    "        print(f\"TEXT: {self.title}\")\n",
    "        for line in self.lines:\n",
    "            print()\n",
    "            line.reformat()\n",
    "    \n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class Document:\n",
    "    texts: List[Text] = field(default_factory=list)\n",
    "    \n",
    "    def reformat(self):\n",
    "        for text in self.texts:\n",
    "            print()\n",
    "            text.reformat()\n",
    "    \n",
    "    \n",
    "    \n",
    "@dataclass\n",
    "class Corpus:\n",
    "    documents: List[Document] = field(default_factory=list)\n",
    "    \n",
    "    def reformat(self):\n",
    "        for i, doc in enumerate(self.documents):\n",
    "            print(f\"DOCUMENT {i}\")\n",
    "            doc.reformat()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edeb95f1-6105-4ab9-8438-ac555dff2690",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class CorpusBuilder:\n",
    "    curr_corpus: Corpus = field(default_factory=Corpus)\n",
    "    curr_doc: Document = field(init=False)\n",
    "    curr_tex: Text = field(init=False)\n",
    "    curr_line: Line = field(init=False)\n",
    "    \n",
    "    def add_word(self, word: Word) -> None:\n",
    "        self.curr_line.words.append(word)\n",
    "        \n",
    "    def start_line(self) -> None:\n",
    "        self.curr_line = Line()\n",
    "    \n",
    "    def end_line(self) -> None:\n",
    "        self.curr_text.lines.append(self.curr_line)\n",
    "    \n",
    "    def start_text(self, title: str) -> None:\n",
    "        self.curr_text = Text(title)\n",
    "        \n",
    "    def end_text(self) -> None:\n",
    "        self.curr_doc.texts.append(self.curr_text)\n",
    "        \n",
    "    def start_doc(self) -> None:\n",
    "        self.curr_doc = Document()\n",
    "        \n",
    "    def end_doc(self) -> None:\n",
    "        self.curr_corpus.documents.append(self.curr_doc)\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        self.curr_corpus = Corpus()\n",
    "    \n",
    "    def build(self) -> Corpus:\n",
    "        return self.curr_corpus\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a38bf217-a8d9-4e92-a30f-cac55c63c300",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing_extensions import Protocol\n",
    "\n",
    "\n",
    "DOC_TAG = 'document'\n",
    "TEXT_TAG = 'text'\n",
    "DIV_TAG = 'div'\n",
    "PARAGRAPH_TAG = 'p'\n",
    "\n",
    "PART_FILE_ROOT = r'parts/'\n",
    "\n",
    "WORD_PATTERN = re.compile(r'(?P<word_forms>.+?)¦(?P<lemma1>.*?)¦?'\n",
    "                               r'.*?¦(?P<lemma2>.*?)¦.*?¦(?P<pos_tags>.+?)¦\\s*(?P<title>.+)', re.DOTALL)\n",
    "START_TAG_PATTERN = re.compile(r'<(?P<tag>\\w+)(?P<attributes>(\\s*?\\w+?=.+?)*)>\\s+(?P<title>.+)', \tre.DOTALL)\n",
    "END_TAG_PATTERN = re.compile(r'<(/?(?P<tag>\\w+)/?)>\\s+(?P<title>.+)', \tre.DOTALL)\n",
    "\n",
    "\n",
    "class CorpusParser(Protocol):\n",
    "    \n",
    "    def feed(self, line: str) -> None:\n",
    "        pass\n",
    "    \n",
    "@dataclass\n",
    "class CorpusParser:\n",
    "    builder: CorpusBuilder = field(default_factory=CorpusBuilder)\n",
    "    tag_stack: List[str] = field(default_factory=list)\n",
    "    \n",
    "    def handle_starttag(self, match: re.Match):\n",
    "        tag = match.groupdict()['tag']\n",
    "        # if tag == DOC_TAG:\n",
    "        #     print(tag, match.group())\n",
    "        self.tag_stack.append(tag)  # add tag on top of the stack, marking start of the tag\n",
    "        if tag == DOC_TAG:\n",
    "            self.builder.start_doc()\n",
    "        elif tag == TEXT_TAG:\n",
    "            self.builder.start_text(match.groupdict()['title'])\n",
    "        elif tag == DIV_TAG:\n",
    "            self.builder.start_line()\n",
    "                \n",
    "    def handle_endtag(self, match: re.Match):\n",
    "        tag = match.groupdict()['tag']\n",
    "        # if tag == DOC_TAG:\n",
    "        #     print(tag, match.group())\n",
    "        try:\n",
    "            self.tag_stack.pop()  ## remove tag from the top of the stack, marking end of the tag\n",
    "        except Exception:\n",
    "            print(tag, match.group())\n",
    "        if tag == DOC_TAG:\n",
    "            self.builder.end_doc()\n",
    "        elif tag == TEXT_TAG:\n",
    "            self.builder.end_text()\n",
    "        elif tag == DIV_TAG:\n",
    "            self.builder.end_line()\n",
    "            \n",
    "    def handle_parts(self, parts: List[str]):\n",
    "        title = parts[-1]\n",
    "        word_forms = parts[0]\n",
    "        word_forms = word_forms.split()\n",
    "        init_form = \" \".join(word_forms[:len(word_forms) // 2 ])\n",
    "        ext_form = \" \".join(word_forms[len(word_forms) // 2: ])\n",
    "        pos_tags = parts[-2].split()\n",
    "        lemma_basic = parts[1]\n",
    "        lemma_adv = parts[3]\n",
    "        # print(init_form)\n",
    "        # print(ext_form)\n",
    "        # print(lemma_basic)\n",
    "        # print(lemma_adv)\n",
    "        # print(title)\n",
    "        # print(pos_tags)\n",
    "        word = Word(init_form, ext_form, lemma_basic, lemma_adv, title, pos_tags)\n",
    "        self.builder.add_word(word)\n",
    "\n",
    "    def handle_word(self, line: str):\n",
    "        curr_tag = self.tag_stack[-1]\n",
    "        if curr_tag == PARAGRAPH_TAG or curr_tag == DIV_TAG:\n",
    "            parts = line.split('¦')\n",
    "            self.handle_parts(parts)\n",
    "            # print(parts)\n",
    "            # pp.pprint(line)\n",
    "            \n",
    "    def finish_corpus(self) -> Corpus:\n",
    "        corpus = self.builder.build()\n",
    "        self.builder.reset()\n",
    "        return corpus\n",
    "            \n",
    "    def feed(self, line: str) -> None:\n",
    "        open_tag_match = START_TAG_PATTERN.match(line)\n",
    "        closed_tag_match = END_TAG_PATTERN.match(line)\n",
    "        if open_tag_match is not None:\n",
    "            self.handle_starttag(open_tag_match)\n",
    "        elif closed_tag_match is not None:\n",
    "            self.handle_endtag(closed_tag_match)\n",
    "        else:\n",
    "            self.handle_word(line)\n",
    "            \n",
    "        \n",
    "    \n",
    "            \n",
    "DEFAULT_DOC_PER_FILE = 50000\n",
    "@dataclass\n",
    "class FileDivider:\n",
    "    root: str = field(default=PART_FILE_ROOT)\n",
    "    doc_per_file: int = field(default=DEFAULT_DOC_PER_FILE)\n",
    "    curr: int = field(init=False, default=0)\n",
    "    doc_count: int = field(init=False, default=0)\n",
    "    \n",
    "    def handle_starttag(self, match: re.Match):\n",
    "        tag = match.groupdict()['tag']\n",
    "        if tag == DOC_TAG and self.doc_count == 0:\n",
    "            self.curr_f = open(f\"{self.root}part{self.curr}.txt\", \"w\")\n",
    "                \n",
    "    def handle_endtag(self, match: re.Match):\n",
    "        tag = match.groupdict()['tag']\n",
    "        if tag == DOC_TAG:\n",
    "            self.doc_count += 1\n",
    "            if self.doc_per_file == self.doc_count:\n",
    "                self.curr_f.close()\n",
    "                self.doc_count = 0\n",
    "                self.curr += 1\n",
    "                pp.pprint(self.curr)\n",
    "            \n",
    "\n",
    "    def handle_word(self, line: str):\n",
    "         self.curr_f.write(line)\n",
    "            \n",
    "    def feed(self, line: str) -> None:\n",
    "        open_tag_match = START_TAG_PATTERN.match(line)\n",
    "        closed_tag_match = END_TAG_PATTERN.match(line)\n",
    "        if open_tag_match is not None:\n",
    "            self.handle_starttag(open_tag_match)\n",
    "            self.handle_word(line)\n",
    "        elif closed_tag_match is not None:\n",
    "            self.handle_word(line)\n",
    "            self.handle_endtag(closed_tag_match)\n",
    "        else:\n",
    "            self.handle_word(line)\n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038e2d89-bc00-45a1-b0ec-9c24929ea5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# parser = FileDivider()\n",
    "# with open('grc-cwb') as f:\n",
    "#     for number, line in enumerate(f):\n",
    "#         parser.feed(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0adf2532-5a76-4a11-8e80-8debedd75b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class JSONCorpusBuilder(CorpusBuilder):\n",
    "    curr_corpus: Corpus = field(default_factory=JSONCorpus)\n",
    "    \n",
    "    def add_word(self, word: Word) -> None:\n",
    "        word = JSONWord(word.word_init, word.word_mod, word.lemma_basic, word.lemma_adv, word.title, word.pos_tags)\n",
    "        self.curr_line.words.append(word)\n",
    "        \n",
    "    def start_line(self) -> None:\n",
    "        self.curr_line = JSONLine()\n",
    "    \n",
    "    def start_text(self, title: str) -> None:\n",
    "        self.curr_text = JSONText(title)\n",
    "        \n",
    "    def start_doc(self) -> None:\n",
    "        self.curr_doc = JSONDocument()\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        self.curr_corpus = JSONCorpus()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb67daec-dfdc-4c43-8008-7a4d02650a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CSVWord(Word):\n",
    "    def reformat(self):\n",
    "        return [self.word_init, self.word_mod, self.lemma_basic, \n",
    "                self.lemma_adv, self.pos_tags]\n",
    "    \n",
    "class JSONLine(Line):\n",
    "    def reformat(self):\n",
    "        return {\"line\": [{\"word\": word.reformat()} for word in self.words] }\n",
    "\n",
    "\n",
    "class JSONText(Text):\n",
    "    def reformat(self):\n",
    "        return {\"text\": [line.reformat() for line in self.lines]}\n",
    "    \n",
    "\n",
    "class JSONDocument(Document):\n",
    "    def reformat(self):\n",
    "        return {\"doc\": [text.reformat() for text in self.texts]}\n",
    "    \n",
    "    \n",
    "class JSONCorpus(Corpus):\n",
    "    def reformat(self):\n",
    "        return [doc.reformat() for doc in self.documents]\n",
    "    \n",
    "\n",
    "@dataclass\n",
    "class JSONCorpusBuilder(CorpusBuilder):\n",
    "    curr_corpus: Corpus = field(default_factory=JSONCorpus)\n",
    "    \n",
    "    def add_word(self, word: Word) -> None:\n",
    "        word = JSONWord(word.word_init, word.word_mod, word.lemma_basic, word.lemma_adv, word.title, word.pos_tags)\n",
    "        self.curr_line.words.append(word)\n",
    "        \n",
    "    def start_line(self) -> None:\n",
    "        self.curr_line = JSONLine()\n",
    "    \n",
    "    def start_text(self, title: str) -> None:\n",
    "        self.curr_text = JSONText(title)\n",
    "        \n",
    "    def start_doc(self) -> None:\n",
    "        self.curr_doc = JSONDocument()\n",
    "        \n",
    "    def reset(self) -> None:\n",
    "        self.curr_corpus = JSONCorpus()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad947550-befa-42f4-8375-dfb4557121f1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CorpusParser' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/tmp/ipykernel_247973/2200650089.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpusParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJSONCorpusBuilder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdir_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwalk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPART_FILE_ROOT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'CorpusParser' is not defined"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import json\n",
    "parser = CorpusParser(JSONCorpusBuilder())\n",
    "files = []\n",
    "for dir_path, _, filename in os.walk(PART_FILE_ROOT):\n",
    "    files.extend(filename)\n",
    "    \n",
    "CSV_FILES_PATh = r'csv/'\n",
    "JSON_FILES_PATH = r'json/'\n",
    "    \n",
    "for file in files:\n",
    "    source = os.path.join(PART_FILE_ROOT, \"part9.txt\")\n",
    "    dest = os.path.join(JSON_FILES_PATH, f\"{file[:-3]}json\")\n",
    "    print(source)\n",
    "    with open(source, \"r\") as f:\n",
    "        for number, line in enumerate(f):\n",
    "            parser.feed(line)\n",
    "    with open(dest, \"w\") as f:\n",
    "        f.write(json.dumps(parser.finish_corpus().reformat()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55053806-abaa-4c81-87db-4e163e3c2490",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-root-py",
   "name": "workbench-notebooks.m109",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/workbench-notebooks:m109"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
